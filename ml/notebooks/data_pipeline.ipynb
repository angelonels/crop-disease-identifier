{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-md-1",
   "metadata": {},
   "source": [
    "## Cell 1: The Ingestion Toolchain\n",
    "We establish the geographic bounds of our project structure. Since this notebook resides in `notebooks/`, it must traverse up one level to deposit the payload into `dataset/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T17:36:20.574546Z",
     "iopub.status.busy": "2026-02-28T17:36:20.574391Z",
     "iopub.status.idle": "2026-02-28T17:36:21.195768Z",
     "shell.execute_reply": "2026-02-28T17:36:21.195080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project topography initialized. Target directory: /Users/angelonelson/Projects/crop-disease-identifier/ml/dataset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "# Define the absolute architecture of our directory tree\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, 'dataset')\n",
    "FINAL_DATA_DIR = os.path.join(DATASET_DIR, 'PlantVillage')\n",
    "\n",
    "# Ensure the dataset directory exists before we initiate the download\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Project topography initialized. Target directory: {DATASET_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-2",
   "metadata": {},
   "source": [
    "## Cell 2: Download and Extract via kagglehub\n",
    "We use `kagglehub` to download and extract the dataset. Authentication is handled automatically via browser login if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T17:36:21.197639Z",
     "iopub.status.busy": "2026-02-28T17:36:21.197431Z",
     "iopub.status.idle": "2026-02-28T17:37:38.932148Z",
     "shell.execute_reply": "2026-02-28T17:37:38.931234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /Users/angelonelson/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/3.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.04G/2.04G [03:27<00:00, 10.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/angelonelson/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/versions/3\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"abdallahalidev/plantvillage-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-3",
   "metadata": {},
   "source": [
    "## Cell 3: Structural Normalization\n",
    "Copy data from kagglehub cache into our project's `dataset/PlantVillage` directory and flatten any redundant nested directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T17:37:38.936180Z",
     "iopub.status.busy": "2026-02-28T17:37:38.935946Z",
     "iopub.status.idle": "2026-02-28T17:37:53.470679Z",
     "shell.execute_reply": "2026-02-28T17:37:53.468591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing directory structure into project tree...\n",
      "Source resolved to: /Users/angelonelson/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/versions/3\n",
      "Color source resolved to: /Users/angelonelson/.cache/kagglehub/datasets/abdallahalidev/plantvillage-dataset/versions/3/plantvillage dataset/color\n",
      "PlantVillage already exists. Removing and re-copying...\n",
      "Data ready at: /Users/angelonelson/Projects/crop-disease-identifier/ml/dataset/PlantVillage\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalizing directory structure into project tree...\")\n",
    "\n",
    "# Walk down through any PlantVillage nesting in the cache\n",
    "source_dir = path\n",
    "for _ in range(3):\n",
    "    nested = os.path.join(source_dir, 'PlantVillage')\n",
    "    if os.path.exists(nested):\n",
    "        source_dir = nested\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Source resolved to: {source_dir}\")\n",
    "\n",
    "# The actual images reside in the 'color' subdirectory of this specific Kaggle payload\n",
    "source_color_dir = os.path.join(source_dir, 'color')\n",
    "if not os.path.exists(source_color_dir):\n",
    "    source_color_dir = os.path.join(source_dir, 'plantvillage dataset', 'color')\n",
    "\n",
    "print(f\"Color source resolved to: {source_color_dir}\")\n",
    "\n",
    "# Copy ONLY the color directory, which contains the class folders\n",
    "if os.path.exists(FINAL_DATA_DIR):\n",
    "    print(\"PlantVillage already exists. Removing and re-copying...\")\n",
    "    shutil.rmtree(FINAL_DATA_DIR)\n",
    "\n",
    "shutil.copytree(source_color_dir, FINAL_DATA_DIR)\n",
    "\n",
    "# Final flatten if there's still a nested PlantVillage\n",
    "nested_dir = os.path.join(FINAL_DATA_DIR, 'PlantVillage')\n",
    "if os.path.exists(nested_dir):\n",
    "    print(\"Flattening redundant nesting...\")\n",
    "    for item in os.listdir(nested_dir):\n",
    "        shutil.move(os.path.join(nested_dir, item), os.path.join(FINAL_DATA_DIR, item))\n",
    "    os.rmdir(nested_dir)\n",
    "\n",
    "print(f\"Data ready at: {FINAL_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-md-4",
   "metadata": {},
   "source": [
    "## Cell 4: The Agronomic Audit (Sanity Check)\n",
    "Before we feed this to a neural network, we must empirically verify the integrity of the data. How many images do we actually have? What is the severity of the class imbalance? This computational audit proves why we mathematically require Focal Loss in the subsequent `mainmodel.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-28T17:37:53.477373Z",
     "iopub.status.busy": "2026-02-28T17:37:53.477066Z",
     "iopub.status.idle": "2026-02-28T17:37:53.534634Z",
     "shell.execute_reply": "2026-02-28T17:37:53.533545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audit complete. Total verified images: 54305\n",
      "Total distinct crop/disease classifications: 38\n",
      "\n",
      "Top 5 Dominant Classes (The Majority):\n",
      "                                Taxonomy  Image Count\n",
      "Orange___Haunglongbing_(Citrus_greening)         5507\n",
      "  Tomato___Tomato_Yellow_Leaf_Curl_Virus         5357\n",
      "                       Soybean___healthy         5090\n",
      "                  Peach___Bacterial_spot         2297\n",
      "                 Tomato___Bacterial_spot         2127\n",
      "\n",
      "Bottom 5 Underrepresented Classes (The Minority):\n",
      "                    Taxonomy  Image Count\n",
      "Tomato___Tomato_mosaic_virus          373\n",
      "         Raspberry___healthy          371\n",
      "             Peach___healthy          360\n",
      "    Apple___Cedar_apple_rust          275\n",
      "            Potato___healthy          152\n"
     ]
    }
   ],
   "source": [
    "class_counts = {}\n",
    "total_images = 0\n",
    "\n",
    "# Traverse the finalized directory and count the JPGs\n",
    "for class_name in os.listdir(FINAL_DATA_DIR):\n",
    "    class_path = os.path.join(FINAL_DATA_DIR, class_name)\n",
    "    \n",
    "    # Ignore hidden system files like .DS_Store\n",
    "    if os.path.isdir(class_path):\n",
    "        num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        class_counts[class_name] = num_images\n",
    "        total_images += num_images\n",
    "\n",
    "# Convert to a DataFrame for an elegant, readable output\n",
    "df_stats = pd.DataFrame(list(class_counts.items()), columns=['Taxonomy', 'Image Count'])\n",
    "df_stats = df_stats.sort_values(by='Image Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"Audit complete. Total verified images: {total_images}\")\n",
    "print(f\"Total distinct crop/disease classifications: {len(df_stats)}\\n\")\n",
    "print(\"Top 5 Dominant Classes (The Majority):\")\n",
    "print(df_stats.head(5).to_string(index=False))\n",
    "print(\"\\nBottom 5 Underrepresented Classes (The Minority):\")\n",
    "print(df_stats.tail(5).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
